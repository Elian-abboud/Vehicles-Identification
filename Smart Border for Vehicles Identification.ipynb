{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmIuyS6QfI7X",
        "outputId": "686fbe29-d076-4bd9-a160-67ed6ad2a60f"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AL42Z_-UmSV",
        "outputId": "efae3f64-e5dd-4c54-8fea-99a53021fec5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpO7As3DTJQx",
        "outputId": "ba3c6bf0-0ade-43d6-c31b-437381b81548"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNPPgnAAQPGY",
        "outputId": "b19b0089-2098-4687-a765-49c072efe857"
      },
      "outputs": [],
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3e5xJrpQZII"
      },
      "outputs": [],
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYvO9b7LQgup"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-7nZ9xQoso",
        "outputId": "c8bdea21-9d9a-4a60-a85b-a6f4dd378d74"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKuDnOIxsN6l"
      },
      "outputs": [],
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSy1EEx0Q8bS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bfc5SjYGPYlb",
        "outputId": "3e2609a9-297d-4d2e-cb1b-813e963976b5"
      },
      "outputs": [],
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator('/content/drive/MyDrive/videos for system/2.mp4')\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AWj7vOCSueO",
        "outputId": "54b16efc-5204-48b2-f76c-5d4b6b2a1361"
      },
      "outputs": [],
      "source": [
        "#####هذا الكود\n",
        "import cv2\n",
        "from ultralytics import YOLO, solutions\n",
        "\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "names = model.model.names\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/videos for system/2.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define region points\n",
        "region_points = [(1000, 1000), (3000, 1000), (3000, 900), (1000, 900)]\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"/content/drive/MyDrive/videos for system/newelian2.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Init Object Counter\n",
        "counter = solutions.ObjectCounter(\n",
        "    view_img=True,\n",
        "    reg_pts=region_points,\n",
        "    classes_names=model.names,\n",
        "    draw_tracks=True,\n",
        "    line_thickness=5,\n",
        ")\n",
        "\n",
        "# Init speed-estimation obj\n",
        "line_pts = [(1000, 950), (3000, 950)]\n",
        "speed_obj = solutions.SpeedEstimator(\n",
        "    reg_pts=line_pts,\n",
        "    names=names,\n",
        "    view_img=True,\n",
        "    line_thickness=5,\n",
        ")\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    tracks = model.track(im0, persist=True, show=False,classes=[2, 3, 5, 7])\n",
        "\n",
        "    im0 = counter.start_counting(im0, tracks)\n",
        "    im0 = speed_obj.estimate_speed(im0, tracks)\n",
        "    video_writer.write(im0)\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2d_PeLf5MK7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "from tkinter import font as tkfont\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Define the car information\n",
        "car_info = {\n",
        "    \"Hyundai i30 FastBack 2018\": {\n",
        "        \"input_image_path\": \"s.png\",\n",
        "        \"dataset_folder\": \"/content/drive/MyDrive/data_crop\"\n",
        "    },\n",
        "    \"Hyundai i30 Wagon 2013\": {\n",
        "        \"input_image_path\": \"ima21ges.png\",\n",
        "        \"dataset_folder\": \"/content/drive/MyDrive/data_crop\"\n",
        "    },\n",
        "    \"Škoda Octavia III 2017\": {\n",
        "        \"input_image_path\": \"Captursswqe.PNG\",\n",
        "        \"dataset_folder\": \"/content/drive/MyDrive/data_crop\"\n",
        "    },\n",
        "     \"kia rio\": {\n",
        "        \"input_image_path\": \"/content/drive/MyDrive/ff.png\",\n",
        "        \"dataset_folder\": \"/content/drive/MyDrive/data_crop\"\n",
        "    }\n",
        "    # Add more car information as needed\n",
        "}\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img[..., ::-1]  # Convert BGR to RGB\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = tf.keras.applications.resnet50.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def extract_features(img_path, model):\n",
        "    img = preprocess_image(img_path)\n",
        "    features = model.predict(img)\n",
        "    return features.flatten()\n",
        "\n",
        "def find_similar_images(input_image_path, dataset_folder, model, threshold=0.7):\n",
        "    \"\"\"\n",
        "    Finds images in the dataset with a similarity score above the given threshold.\n",
        "\n",
        "    Args:\n",
        "        input_image_path (str): Path to the input image.\n",
        "        dataset_folder (str): Path to the folder containing the dataset images.\n",
        "        model (tf.keras.Model): The pre-trained model for feature extraction.\n",
        "        threshold (float): The minimum similarity score for an image to be considered a match.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of paths to images with similarity scores above the threshold.\n",
        "    \"\"\"\n",
        "    input_features = extract_features(input_image_path, model)\n",
        "    similar_images = []\n",
        "\n",
        "    for img_file in os.listdir(dataset_folder):\n",
        "        img_path = os.path.join(dataset_folder, img_file)\n",
        "        if img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            dataset_features = extract_features(img_path, model)\n",
        "            similarity = cosine_similarity([input_features], [dataset_features])[0][0]\n",
        "            if similarity >= threshold:\n",
        "                similar_images.append((img_path, similarity))\n",
        "\n",
        "    return similar_images\n",
        "\n",
        "def process_image():\n",
        "    selected_car = car_var.get()\n",
        "    if selected_car in car_info:\n",
        "        input_image_path = car_info[selected_car][\"input_image_path\"]\n",
        "        dataset_folder = car_info[selected_car][\"dataset_folder\"]\n",
        "\n",
        "        similar_images = find_similar_images(input_image_path, dataset_folder, model)\n",
        "\n",
        "        if similar_images:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            for i, (img_path, similarity) in enumerate(similar_images):\n",
        "                similar_img = cv2.imread(img_path)\n",
        "                similar_img = cv2.cvtColor(similar_img, cv2.COLOR_BGR2RGB)\n",
        "                plt.subplot(len(similar_images), 1, i+1)\n",
        "                plt.title(f'Similar Image {i+1}\\nSimilarity: {similarity:.4f}')\n",
        "                plt.imshow(similar_img)\n",
        "                plt.axis('off')\n",
        "            error_label.config(text=\"Success.\")\n",
        "            plt.show()\n",
        "            error_label.config(text=\"\")  # Clear any previous error message\n",
        "        else:\n",
        "            error_label.config(text=\"No images found with similarity above 70%.\")\n",
        "    else:\n",
        "        error_label.config(text=\"Please select a valid car.\")\n",
        "\n",
        "# Create the main window\n",
        "root = tk.Tk()\n",
        "root.title(\"Image Similarity Search\")\n",
        "\n",
        "# Set custom font for the application\n",
        "custom_font = tkfont.Font(family=\"Arial\", size=12, weight=\"bold\")\n",
        "\n",
        "# Create a dropdown list for car selection\n",
        "car_var = tk.StringVar(root)\n",
        "car_var.set(list(car_info.keys())[0])  # Set the default selection to the first car\n",
        "car_dropdown = ttk.Combobox(root, textvariable=car_var, values=list(car_info.keys()), font=custom_font)\n",
        "car_dropdown.grid(row=0, column=0, padx=10, pady=10)\n",
        "\n",
        "# Create a button to trigger the image processing\n",
        "process_button = tk.Button(root, text=\"Process Image\", command=process_image, font=custom_font)\n",
        "process_button.grid(row=1, column=0, padx=10, pady=10)\n",
        "\n",
        "# Create a label to display any error messages\n",
        "error_label = tk.Label(root, text=\"\", fg=\"red\", font=custom_font)\n",
        "error_label.grid(row=2, column=0, padx=10, pady=10)\n",
        "\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "glaYV3x2ds4I",
        "outputId": "83f4ce92-1686-492d-8b02-e04bdcad9a61"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.solutions import object_counter, speed_estimation\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "names = model.model.names\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Video/Trim2.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Video writer\n",
        "combined_video_writer = cv2.VideoWriter(\"combined_output2.avi\",\n",
        "                                        cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                                        fps,\n",
        "                                        (w, h))\n",
        "\n",
        "region_points = [(500, 1100), (3500, 1100), (1080, 360), (20, 360)]\n",
        "# Define line points for speed estimation\n",
        "line_pts = [(500, 1100), (3500, 1100)]\n",
        "\n",
        "# Init Object Counter\n",
        "counter = object_counter.ObjectCounter()\n",
        "counter.set_args(view_img=True,\n",
        "                 reg_pts=region_points,\n",
        "                 classes_names=model.names,\n",
        "                 draw_tracks=True,\n",
        "                 line_thickness=1,view_in_counts=True,view_out_counts=True)\n",
        "\n",
        "# Init Speed Estimator\n",
        "speed_obj = speed_estimation.SpeedEstimator()\n",
        "speed_obj.set_args(reg_pts=line_pts,\n",
        "                   names=names,\n",
        "                   view_img=True)\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    tracks = model.track(im0, persist=True, show=False)\n",
        "\n",
        "    # Object counting\n",
        "    im0_object_counting = counter.start_counting(im0, tracks)\n",
        "\n",
        "    # Speed estimation\n",
        "    im0_speed_estimation = speed_obj.estimate_speed(im0_object_counting, tracks)\n",
        "\n",
        "    # Combine images\n",
        "    combined_image = cv2.addWeighted(im0_object_counting, 0.5, im0_speed_estimation, 0.5, 0)\n",
        "\n",
        "    combined_video_writer.write(combined_image)\n",
        "\n",
        "cap.release()\n",
        "combined_video_writer.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4mzpMZ7BeqPM",
        "outputId": "7bac2f6c-ff71-496c-9932-15b822157776"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "model = YOLO(\"yolov8x\")\n",
        "names = model.names\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Trim.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "crop_dir_name = \"/content/drive/MyDrive/data_crop3\"\n",
        "if not os.path.exists(crop_dir_name):\n",
        "    os.mkdir(crop_dir_name)\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"object_cropping_output.avi\",\n",
        "                               cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                               fps, (w, h))\n",
        "\n",
        "idx = 0\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    results = model.predict(im0, show=False)\n",
        "    boxes = results[0].boxes.xyxy.cpu().tolist()\n",
        "    clss = results[0].boxes.cls.cpu().tolist()\n",
        "    annotator = Annotator(im0, line_width=2, example=names)\n",
        "\n",
        "    if boxes is not None:\n",
        "        for box, cls in zip(boxes, clss):\n",
        "            idx += 1\n",
        "            annotator.box_label(box, color=colors(int(cls), True), label=names[int(cls)])\n",
        "\n",
        "            crop_obj = im0[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
        "\n",
        "            cv2.imwrite(os.path.join(crop_dir_name, str(idx)+\".png\"), crop_obj)\n",
        "\n",
        "\n",
        "    video_writer.write(im0)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRyEAectdNji"
      },
      "outputs": [],
      "source": [
        "# save pipe.pkl to output data folder\n",
        "!cp -r /content/uy.avi /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11_Y6XFbdse7",
        "outputId": "686df156-40b6-4d14-907c-fda1c7da56e6"
      },
      "outputs": [],
      "source": [
        "!zip -r dataset.zip ultralytics_crop/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
